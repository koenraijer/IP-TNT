{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, '../Analysis')\n",
    "\n",
    "import helpers as h\n",
    "import empatica_helpers as eh\n",
    "import inquisit_helpers as ih\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "reload(h), reload(eh), reload(ih)\n",
    "\n",
    "# Global settings\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "plt.style.use('seaborn-v0_8-notebook') # plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# print(plt.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  80.23809523809524\n",
      "Val size:  8.333333333333332\n",
      "Test size:  11.428571428571429\n",
      "Size: : (1011, 768, 6)\n"
     ]
    }
   ],
   "source": [
    "reload(eh), reload(ih), reload(h)\n",
    "\n",
    "sr = 32\n",
    "wl = 24 # Window length in seconds\n",
    "\n",
    "# Full pipeline\n",
    "# e_raw, _ = eh.load_empatica(data_folder='input/empatica/', useIBI=False, save=True, plotTrimmings=False, desired_sampling_rate=sr)\n",
    "# i_raw = ih.load_inquisit(data_folder='input/inquisit/', save=True)\n",
    "# ei_raw = h.combine_empatica_and_inquisit(e_raw, i_raw, save=True, sr=sr)\n",
    "# ei_prep = h.clean_scale_filter(save=True, normalise=True, sr=sr, window_length=wl)\n",
    "# X, y, p = h.prepare_for_vae(sr=sr, wl=wl, filepath=\"output/ei_prep.csv\", save=True)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, p_train, p_val, p_test = h.prepare_train_val_test_sets(filenames=['output/dl_X_wl24_sr32.pkl', 'output/dl_y_wl24_sr32.pkl', 'output/dl_p_wl24_sr32.pkl'])\n",
    "\n",
    "# Back to input for ML models\n",
    "# X_train_aggregates = h.prepare_for_ml(X_train)\n",
    "# X_val_aggregates = h.prepare_for_ml(X_val)\n",
    "# X_test_aggregates = h.prepare_for_ml(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1011, 36)\n",
      "(1011, 768, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koenraijer/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/helpers.py:399: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  for train_index, test_index in gkf.split(X_train, y_train, groups):\n"
     ]
    }
   ],
   "source": [
    "reload(h)\n",
    "\n",
    "# Calculate the aggregates for the training set\n",
    "X_train_aggregates = h.prepare_for_ml(X_train)\n",
    "\n",
    "print(X_train_aggregates.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On VAE preprocessing**\n",
    "\n",
    "The model expects data as a Numpy array with dimensions [samples, time points, variables]. My data is a multivariate timeseries with binary labels. It is sampled at 64 Hz. I think this means I should take labelled slices of my data that describe a multivariate timeseries at several timepoints. So if I'm looking to use an 8s sample that is labelled intrusion or not, I get [sample_index, 0:512, n_features] per sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NON-CLASS IMPLEMENTATION: Conditional recurrent (LSTM) VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='total_loss', mode=\"min\", patience=4)\n",
    "\n",
    "vae = LSTM_VAE(input_shape=X_train.shape, int_dim=64, latent_dim=12)\n",
    "vae.compile(optimizer='adam')\n",
    "history = vae.fit(x=X_train, y=y_train, epochs=100, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras, shape\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import(LSTM, Dense, Input, Lambda, RepeatVector, TimeDistributed, Concatenate)\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_lstm_vae_model(time_steps, number_of_features, int_dim, latent_dim, condition_dim):\n",
    "    \"\"\"\n",
    "    Creates a conditional LSTM Variational Autoencoder (VAE) model.\n",
    "\n",
    "    Parameters:\n",
    "    - time_steps (int): The number of time steps in the input sequence.\n",
    "    - number_of_features (int): The number of features in the input sequence.\n",
    "    - int_dim (int): The dimensionality of the intermediate LSTM layer.\n",
    "    - latent_dim (int): The dimensionality of the latent space.\n",
    "    - condition_dim (int): The dimensionality of the condition.\n",
    "\n",
    "    Returns:\n",
    "    - encoder (Model): The encoder model.\n",
    "    - decoder (Model): The decoder model.\n",
    "    - lstm_vae (Model): The LSTM VAE model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def vae_sampling(args):\n",
    "        \"\"\"\n",
    "        Sampling function for the VAE.\n",
    "\n",
    "        Parameters:\n",
    "        - args (tuple): Tuple containing the mean and log variance of the latent space.\n",
    "\n",
    "        Returns:\n",
    "        - Sampled latent space vector.\n",
    "\n",
    "        \"\"\"\n",
    "        z_mean, z_log_sigma = args\n",
    "        batch_size = shape(z_mean)[0]\n",
    "        latent_dim = shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0, stddev=1)\n",
    "        return z_mean + K.exp(z_log_sigma / 2) * epsilon\n",
    "\n",
    "    # Encoder\n",
    "    input_x = Input(shape=(time_steps, number_of_features))\n",
    "    condition_input = Input(shape=(condition_dim,))\n",
    "    encoder_input = Concatenate()([input_x, RepeatVector(time_steps)(condition_input)])\n",
    "\n",
    "    encoder_LSTM_int = LSTM(int_dim, return_sequences=True)(encoder_input)\n",
    "    encoder_LSTM_latent = LSTM(latent_dim, return_sequences=False)(encoder_LSTM_int)\n",
    "\n",
    "    z_mean = Dense(latent_dim)(encoder_LSTM_latent)\n",
    "    z_log_sigma = Dense(latent_dim)(encoder_LSTM_latent)\n",
    "    z_encoder_output = Lambda(vae_sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "\n",
    "    encoder = Model([input_x, condition_input], [z_mean, z_log_sigma, z_encoder_output])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    decoder_condition_input = Input(shape=(condition_dim,))\n",
    "    decoder_repeated = RepeatVector(time_steps)(Concatenate()([decoder_input, decoder_condition_input]))\n",
    "\n",
    "    decoder_LSTM_int = LSTM(int_dim, return_sequences=True)(decoder_repeated)\n",
    "    decoder_LSTM = LSTM(number_of_features, return_sequences=True)(decoder_LSTM_int)\n",
    "    decoder_output = TimeDistributed(Dense(number_of_features))(decoder_LSTM)\n",
    "    decoder = Model([decoder_input, decoder_condition_input], decoder_output)\n",
    "\n",
    "    # VAE\n",
    "    output = decoder([encoder([input_x, condition_input])[2], condition_input])\n",
    "    lstm_vae = keras.Model([input_x, condition_input], output, name='lstm_vae')\n",
    "\n",
    "    # Loss\n",
    "    rec_loss = K.mean(mse(input_x, output)) * number_of_features\n",
    "    kl_loss = -0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "    vae_loss = rec_loss + kl_loss\n",
    "\n",
    "    lstm_vae.add_loss(vae_loss)\n",
    "\n",
    "    return encoder, decoder, lstm_vae\n",
    "\n",
    "def generate_lstm_vae_samples(decoder, n, latent_dim, condition):\n",
    "    '''\n",
    "        Generate random samples from the LSTM VAE.\n",
    "\n",
    "        n : int\n",
    "            The number of samples to generate.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A numpy array of shape (n, time_steps, number_of_features) containing the generated samples.\n",
    "    '''\n",
    "    # Sample from the standard normal distribution\n",
    "    z_samples = np.random.normal(size=(n, latent_dim))\n",
    "\n",
    "    # Decode the samples\n",
    "    gen = decoder.predict([z_samples, np.repeat(condition, n, axis=0)])\n",
    "\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating new data from the VAE's latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of samples to generate for each class\n",
    "n_samples = 500\n",
    "\n",
    "# Define the conditions for each class\n",
    "condition_0 = np.array([[0]])\n",
    "condition_1 = np.array([[1]])\n",
    "\n",
    "# Generate samples for each class\n",
    "samples_0 = generate_lstm_vae_samples(decoder, n_samples, latent_dim, condition_0)\n",
    "samples_1 = generate_lstm_vae_samples(decoder, n_samples, latent_dim, condition_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a non-conditional LSTM-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import shape\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Source: https://github.com/meliksahturker/LSTM-VAE/tree/main?tab=readme-ov-file \n",
    "\n",
    "class LSTM_VAE(keras.Model):\n",
    "    def __init__(self, input_shape, int_dim, latent_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.int_dim = int_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_features = input_shape[2]\n",
    "        self.time_steps = input_shape[1]\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    def build_encoder(self):\n",
    "        \"\"\"\n",
    "        Builds the encoder part of the VAE.\n",
    "        \"\"\"\n",
    "\n",
    "        def Sampling(args):\n",
    "            \"\"\"\n",
    "            Sampling function for the VAE.\n",
    "            Parameters: args (tuple): Tuple containing the mean and log variance of the latent space.\n",
    "            Returns: Sampled latent space vector.\n",
    "            \"\"\"\n",
    "            z_mean, z_log_var = args\n",
    "            batch_size = shape(z_mean)[0] # Number of samples in the batch\n",
    "            latent_dim = shape(z_mean)[1] # Dimensionality of the latent space\n",
    "            epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0, stddev=1) # epsilon = irreducible error. Generates random noise to add to our reparameterisation trick value\n",
    "            # Reparameterisation trick\n",
    "            # - `K.exp()` takes the exponential of our log variance to obtain the variance. \n",
    "            # - `z_log_var / 2` is equivalent to taking the square root of the variance (standard deviation)\n",
    "            # - `* epsilon` to get a random value from a normal distribution with mean 0 and standard deviation 1\n",
    "            return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "        # --------------------- ENCODER ---------------------\n",
    "        x = Input(shape=(self.time_steps, self.num_features))  # Keras adds None to the shape for the batch size: (None, time_steps, number_of_features)\n",
    "        encoder_LSTM_intermediate = LSTM(self.int_dim, return_sequences=True, name=\"encoder_LSTM_intermediate\")(x)\n",
    "        encoder_LSTM_latent = LSTM(self.latent_dim, return_sequences=False, name=\"encoder_LSTM_latent\")(encoder_LSTM_intermediate)\n",
    "\n",
    "        # These layers' outputs will be trained to represent the mean and log variance of the latent space\n",
    "        z_mean = Dense(self.latent_dim, name=\"z_mean\")(encoder_LSTM_latent) # Mean(s) of the latent space\n",
    "        z_log_var = Dense(self.latent_dim, name=\"z_log_var\")(encoder_LSTM_latent) # Log variance(s) of the latent space. Log is used to ensure so its exponent (which we'll calculate later) is always positive.\n",
    "\n",
    "        # A Lambda layer is used to sample from the latent space by passing the mean and log variance to the vae_sampling function\n",
    "        z = Lambda(Sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "        encoder = Model(inputs=x, outputs=[z_mean, z_log_var, z], name=\"encoder\") # z_mean and z_log_sigma are returned for loss calculation, z_encoder_output is the output of the encoder and will be used as input to the decoder\n",
    "\n",
    "        # SIDENOTE: Keras is able to trace back the computation graph from the output of the encoder to the input, so it will infer the structure of the encoder from its output and input layers.\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def build_decoder(self):\n",
    "        \"\"\"\n",
    "        Builds the decoder part of the VAE.\n",
    "        \"\"\"\n",
    "        decoder_input = Input(shape=(self.latent_dim,)) # Input to the decoder is the latent space vector z\n",
    "        decoder_repeated = RepeatVector(self.time_steps)(decoder_input) # Repeats the latent space vector (z) for the number of time steps, to match the input shape of the LSTM.\n",
    "        decoder_LSTM_intermediate = LSTM(self.int_dim, return_sequences=True)(decoder_repeated) # Transforms (batch_size, time_steps, latent_dim) to (batch_size, time_steps, int_dim). \n",
    "        decoder_LSTM = LSTM(self.num_features, return_sequences=True)(decoder_LSTM_intermediate) # Transforms (batch_size, time_steps, int_dim) to (batch_size, time_steps, number_of_features). \n",
    "        decoder_output = TimeDistributed(Dense(self.num_features))(decoder_LSTM) # Contains Dense layer at the end to be able to produce high absolute values, since LSTM activations are tanh.\n",
    "        decoder = Model(inputs=decoder_input, outputs=decoder_output, name=\"decoder\") \n",
    "\n",
    "        return decoder\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "            \"\"\"\n",
    "            Returns a list of metrics used for tracking during training.\n",
    "            Returns:list: A list of metrics including total loss, reconstruction loss, and KL divergence loss.\n",
    "            \"\"\"\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker,\n",
    "            ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Performs a single training step on the given data.\n",
    "        Args: data: The input data for training.\n",
    "        Returns: A dictionary containing the following metrics: loss; The total loss value, reconstruction_loss; The reconstruction loss value, kl_loss; The KL divergence loss value.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(data, reconstruction),\n",
    "                    axis=(0, 1),\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the model.\n",
    "        Args: inputs: The input data.\n",
    "        Returns: The reconstructed output.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "    def test_step(self, data):\n",
    "        \"\"\"\n",
    "        Performs a single testing step of the model.\n",
    "        Args: data: The input data for testing.\n",
    "        Returns: A dictionary containing the loss values for the total loss, reconstruction loss, and KL divergence loss.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.mse(data, reconstruction),\n",
    "                axis=(0, 1),\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def generate_samples(self, n):\n",
    "        '''\n",
    "            Generate random samples from the LSTM VAE.\n",
    "\n",
    "            n : int\n",
    "                The number of samples to generate.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            A numpy array of shape (n, time_steps, number_of_features) containing the generated samples.\n",
    "        '''\n",
    "        import numpy as np\n",
    "\n",
    "        # Sample from the standard normal distribution\n",
    "        z_samples = np.random.normal(size=(n, self.latent_dim))\n",
    "\n",
    "        # Decode the samples\n",
    "        gen = self.decoder.predict(z_samples)\n",
    "\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a conditional LSTM-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koenraijer/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/.conda/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/koenraijer/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/.conda/lib/python3.11/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.16.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, LSTM, Dense, RepeatVector, TimeDistributed\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeepholeLSTMCell\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Source: https://github.com/meliksahturker/LSTM-VAE/tree/main?tab=readme-ov-file \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLSTM_VAE\u001b[39;00m(Model):\n",
      "File \u001b[0;32m~/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/.conda/lib/python3.11/site-packages/tensorflow_addons/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m _check_tf_version()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[0;32m~/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/.conda/lib/python3.11/site-packages/tensorflow_addons/activations/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgelu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhardshrink\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlisht\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lisht\n",
      "File \u001b[0;32m~/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/.conda/lib/python3.11/site-packages/tensorflow_addons/activations/gelu.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/.conda/lib/python3.11/site-packages/tensorflow_addons/utils/types.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# importing internal symbols.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Concatenate, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import shape\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.rnn import PeepholeLSTMCell\n",
    "\n",
    "# Source: https://github.com/meliksahturker/LSTM-VAE/tree/main?tab=readme-ov-file \n",
    "\n",
    "class LSTM_VAE(Model):\n",
    "    def __init__(self, input_shape, int_dim, latent_dim, condition_dim=1, seed=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.int_dim = int_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_features = input_shape[2]\n",
    "        self.time_steps = input_shape[1]\n",
    "        self.condition_dim = condition_dim\n",
    "        self.condition_input = Input(shape=(condition_dim,)) # Shape of the condition input\n",
    "\n",
    "        # Everything needed for the encoder and decoder should be defined before calling the encoder and decoder functions\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            tf.random.set_seed(self.seed)\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        \"\"\"\n",
    "        Builds the encoder part of the VAE.\n",
    "        \"\"\"\n",
    "\n",
    "        def Sampling(args):\n",
    "            \"\"\"\n",
    "            Sampling function for the VAE.\n",
    "            Parameters: args (tuple): Tuple containing the mean and log variance of the latent space.\n",
    "            Returns: Sampled latent space vector.\n",
    "            \"\"\"\n",
    "            z_mean, z_log_var = args\n",
    "            batch_size = shape(z_mean)[0] # Number of samples in the batch\n",
    "            latent_dim = shape(z_mean)[1] # Dimensionality of the latent space\n",
    "            epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0, stddev=1) # epsilon = irreducible error. Generates random noise to add to our reparameterisation trick value\n",
    "            # Reparameterisation trick\n",
    "            # - `K.exp()` takes the exponential of our log variance to obtain the variance. \n",
    "            # - `z_log_var / 2` is equivalent to taking the square root of the variance (standard deviation)\n",
    "            # - `* epsilon` to get a random value from a normal distribution with mean 0 and standard deviation 1\n",
    "            return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "        # --------------------- ENCODER ---------------------\n",
    "        # Creating the input layer\n",
    "        x = Input(shape=(self.time_steps, self.num_features))  # Keras adds None to the shape for the batch size: (None, time_steps, number_of_features)\n",
    "        encoder_input = Concatenate()([x, RepeatVector(self.time_steps)(self.condition_input)])\n",
    "\n",
    "        # Creating the LSTM layers\n",
    "        # PeepholeLSTMCell(n_hidden[0], activation=tf.nn.tanh, name=\"encoder\") # Docs: https://www.tensorflow.org/addons/api_docs/python/tfa/rnn/PeepholeLSTMCell\n",
    "        encoder_LSTM_intermediate = LSTM(self.int_dim, return_sequences=True, name=\"encoder_LSTM_intermediate\")(encoder_input)\n",
    "        encoder_LSTM_latent = LSTM(self.latent_dim, return_sequences=False, name=\"encoder_LSTM_latent\")(encoder_LSTM_intermediate)\n",
    "\n",
    "        # These layers' outputs will be trained to represent the mean and log variance of the latent space\n",
    "        z_mean = Dense(self.latent_dim, name=\"z_mean\")(encoder_LSTM_latent) # Mean(s) of the latent space\n",
    "        z_log_var = Dense(self.latent_dim, name=\"z_log_var\")(encoder_LSTM_latent) # Log variance(s) of the latent space. Log is used to ensure so its exponent (which we'll calculate later) is always positive.\n",
    "\n",
    "        # A Lambda layer is used to sample from the latent space by passing the mean and log variance to the vae_sampling function\n",
    "        z = Lambda(Sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "        encoder = Model(inputs=[x, self.condition_input], outputs=[z_mean, z_log_var, z], name=\"encoder\") # z_mean and z_log_sigma are returned for loss calculation, z_encoder_output is the output of the encoder and will be used as input to the decoder\n",
    "\n",
    "        # SIDENOTE: Keras is able to trace back the computation graph from the output of the encoder to the input, so it will infer the structure of the encoder from its output and input layers.\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def build_decoder(self):\n",
    "        \"\"\"\n",
    "        Builds the decoder part of the VAE.\n",
    "        \"\"\"\n",
    "        decoder_input = Input(shape=(self.latent_dim,)) # Input to the decoder is the latent space vector z\n",
    "        condition_input_repeated = Flatten()(RepeatVector(self.latent_dim)(self.condition_input))\n",
    "        decoder_input_concat = Concatenate()([decoder_input, condition_input_repeated])\n",
    "        decoder_repeated = RepeatVector(self.time_steps)(decoder_input_concat) # Repeats the latent space vector (z) for the number of time steps, to match the input shape of the LSTM.\n",
    "        decoder_LSTM_intermediate = LSTM(self.int_dim, return_sequences=True)(decoder_repeated) # Transforms (batch_size, time_steps, latent_dim) to (batch_size, time_steps, int_dim). \n",
    "        decoder_LSTM = LSTM(self.num_features, return_sequences=True)(decoder_LSTM_intermediate) # Transforms (batch_size, time_steps, int_dim) to (batch_size, time_steps, number_of_features). \n",
    "        decoder_output = TimeDistributed(Dense(self.num_features))(decoder_LSTM) # Contains Dense layer at the end to be able to produce high absolute values, since LSTM activations are tanh.\n",
    "        decoder = Model(inputs=[decoder_input, self.condition_input], outputs=decoder_output, name=\"decoder\") \n",
    "        \n",
    "        return decoder\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "            \"\"\"\n",
    "            Returns a list of metrics used for tracking during training.\n",
    "            Returns:list: A list of metrics including total loss, reconstruction loss, and KL divergence loss.\n",
    "            \"\"\"\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker,\n",
    "            ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the model.\n",
    "        Args: inputs: The input data.\n",
    "        Returns: The reconstructed output.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "    def calculate_losses(self, x, condition):\n",
    "        \"\"\"\n",
    "        Calculates the total loss, reconstruction loss, and KL divergence loss for a given input and condition.\n",
    "\n",
    "        Parameters:\n",
    "            x (tensor): The input tensor.\n",
    "            condition (tensor): The condition tensor.\n",
    "\n",
    "        Returns:\n",
    "            total_loss (tensor): The total loss.\n",
    "            reconstruction_loss (tensor): The reconstruction loss.\n",
    "            kl_loss (tensor): The KL divergence loss.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder([x, condition])\n",
    "        reconstruction = self.decoder([z, condition])\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.mse(x, reconstruction),\n",
    "                axis=(0, 1),\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Performs a single training step on the given data.\n",
    "\n",
    "        Args:\n",
    "            data: A tuple containing the input data `x` and the condition `condition`.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the following metrics:\n",
    "            - \"loss\": The total loss value.\n",
    "            - \"reconstruction_loss\": The reconstruction loss value.\n",
    "            - \"kl_loss\": The KL divergence loss value.\n",
    "        \"\"\"\n",
    "        x, condition = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        \"\"\"\n",
    "        Perform a single testing step of the model.\n",
    "\n",
    "        Args:\n",
    "            data (tuple): A tuple containing the input data `x` and the condition `condition`.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the calculated losses for the testing step, including the total loss, reconstruction loss, and KL loss.\n",
    "        \"\"\"\n",
    "        x, condition = data\n",
    "        total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def generate_samples(self, n, condition):\n",
    "        '''\n",
    "            Generate random samples from the LSTM VAE.\n",
    "\n",
    "            n : int : The number of samples to generate.\n",
    "            condition : numpy array : The condition to generate the samples for.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            A numpy array of shape (n, time_steps, number_of_features) containing the generated samples.\n",
    "        '''\n",
    "\n",
    "        # Sample from the standard normal distribution\n",
    "        z_samples = np.random.normal(size=(n, self.latent_dim))\n",
    "\n",
    "        # Decode the samples\n",
    "        gen = self.decoder.predict([z_samples, np.repeat(condition, n, axis=0)])\n",
    "\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Adadelta\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space = {\n",
    "    'int_dim': hp.quniform('int_dim', 32, 256, 1),\n",
    "    'latent_dim': hp.quniform('latent_dim', 2, 20, 1),\n",
    "    'batch_size': 32,\n",
    "}\n",
    "\n",
    "def train_model(params):\n",
    "    # Create the model\n",
    "    vae = LSTM_VAE(input_shape=X_train.shape, int_dim=int(params['int_dim']), latent_dim=int(params['latent_dim']))\n",
    "    vae.compile(optimizer='adam')\n",
    "    early_stopping = EarlyStopping(monitor='total_loss', mode=\"min\", patience=4)\n",
    "    history = vae.fit(x=X_train, y=y_train, batch_size=int(params['batch_size']), callbacks=[early_stopping], epochs=100)\n",
    "    return history.history['total_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "# Objective function\n",
    "def objective(params):\n",
    "    return train_model(params)\n",
    "\n",
    "best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=Trials())\n",
    "\n",
    "print(\"Best parameters found: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added `seed` and `PeepholeLSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Concatenate, Flatten, RNN\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import shape\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.rnn import PeepholeLSTMCell\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Source: https://github.com/meliksahturker/LSTM-VAE/tree/main?tab=readme-ov-file \n",
    "\n",
    "class LSTM_VAE(Model):\n",
    "    def __init__(self, input_shape, int_dim, latent_dim, condition_dim=1, seed=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.int_dim = int_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_features = input_shape[2]\n",
    "        self.time_steps = input_shape[1]\n",
    "        self.condition_dim = condition_dim\n",
    "        self.condition_input = Input(shape=(condition_dim,)) # Shape of the condition input\n",
    "\n",
    "        self.seed = seed\n",
    "        self.layer_seed = 0 \n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            tf.random.set_seed(self.seed)\n",
    "            \n",
    "        # Everything needed for the encoder and decoder should be defined before calling the encoder and decoder functions\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        \"\"\"\n",
    "        Builds the encoder part of the VAE.\n",
    "        \"\"\"\n",
    "\n",
    "        def Sampling(args):\n",
    "            \"\"\"\n",
    "            Sampling function for the VAE.\n",
    "            Parameters: args (tuple): Tuple containing the mean and log variance of the latent space.\n",
    "            Returns: Sampled latent space vector.\n",
    "            \"\"\"\n",
    "            z_mean, z_log_var = args\n",
    "            batch_size = shape(z_mean)[0] # Number of samples in the batch\n",
    "            latent_dim = shape(z_mean)[1] # Dimensionality of the latent space\n",
    "            epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0, stddev=1) # epsilon = irreducible error. Generates random noise to add to our reparameterisation trick value\n",
    "            # Reparameterisation trick\n",
    "            # - `K.exp()` takes the exponential of our log variance to obtain the variance. \n",
    "            # - `z_log_var / 2` is equivalent to taking the square root of the variance (standard deviation)\n",
    "            # - `* epsilon` to get a random value from a normal distribution with mean 0 and standard deviation 1\n",
    "            return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "        # --------------------- ENCODER ---------------------\n",
    "        # Creating the input layer\n",
    "        x = Input(shape=(self.time_steps, self.num_features))  # Keras adds None to the shape for the batch size: (None, time_steps, number_of_features)\n",
    "        encoder_input = Concatenate()([x, RepeatVector(self.time_steps)(self.condition_input)])\n",
    "\n",
    "        # Creating the LSTM layers\n",
    "        encoder_LSTM_intermediate = RNN(PeepholeLSTMCell(self.int_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True, name=\"encoder_LSTM_intermediate\")(encoder_input)\n",
    "        self.layer_seed += 1\n",
    "        encoder_LSTM_latent = RNN(PeepholeLSTMCell(self.latent_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=False, name=\"encoder_LSTM_latent\")(encoder_LSTM_intermediate)\n",
    "        self.layer_seed += 1\n",
    "\n",
    "        # NOTE: GlorotUniform is equivalent to Xavier activation function (recommended with tanh activation functions, the default in LSTMs).\n",
    "\n",
    "        # These layers' outputs will be trained to represent the mean and log variance of the latent space\n",
    "        z_mean = Dense(self.latent_dim, name=\"z_mean\")(encoder_LSTM_latent) # Mean(s) of the latent space\n",
    "        z_log_var = Dense(self.latent_dim, name=\"z_log_var\")(encoder_LSTM_latent) # Log variance(s) of the latent space. Log is used to ensure so its exponent (which we'll calculate later) is always positive.\n",
    "\n",
    "        # A Lambda layer is used to sample from the latent space by passing the mean and log variance to the vae_sampling function\n",
    "        z = Lambda(Sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "        encoder = Model(inputs=[x, self.condition_input], outputs=[z_mean, z_log_var, z], name=\"encoder\") # z_mean and z_log_sigma are returned for loss calculation, z_encoder_output is the output of the encoder and will be used as input to the decoder\n",
    "\n",
    "        # SIDENOTE: Keras is able to trace back the computation graph from the output of the encoder to the input, so it will infer the structure of the encoder from its output and input layers.\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def build_decoder(self):\n",
    "        \"\"\"\n",
    "        Builds the decoder part of the VAE.\n",
    "        \"\"\"\n",
    "        decoder_input = Input(shape=(self.latent_dim,)) # Input to the decoder is the latent space vector z\n",
    "        condition_input_repeated = Flatten()(RepeatVector(self.latent_dim)(self.condition_input))\n",
    "        decoder_input_concat = Concatenate()([decoder_input, condition_input_repeated])\n",
    "        decoder_repeated = RepeatVector(self.time_steps)(decoder_input_concat) # Repeats the latent space vector (z) for the number of time steps, to match the input shape of the LSTM.\n",
    "        decoder_LSTM_intermediate = RNN(PeepholeLSTMCell(self.int_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True)(decoder_repeated) # Transforms (batch_size, time_steps, latent_dim) to (batch_size, time_steps, int_dim). \n",
    "        self.layer_seed += 1\n",
    "        decoder_LSTM = RNN(PeepholeLSTMCell(self.num_features, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True)(decoder_LSTM_intermediate)\n",
    "        decoder_output = TimeDistributed(Dense(self.num_features))(decoder_LSTM) # Contains Dense layer at the end to be able to produce high absolute values, since LSTM activations are tanh.\n",
    "        decoder = Model(inputs=[decoder_input, self.condition_input], outputs=decoder_output, name=\"decoder\") \n",
    "        \n",
    "        return decoder\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "            \"\"\"\n",
    "            Returns a list of metrics used for tracking during training.\n",
    "            Returns:list: A list of metrics including total loss, reconstruction loss, and KL divergence loss.\n",
    "            \"\"\"\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker,\n",
    "            ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the model.\n",
    "        Args: inputs: The input data.\n",
    "        Returns: The reconstructed output.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "    def calculate_losses(self, x, condition):\n",
    "        \"\"\"\n",
    "        Calculates the total loss, reconstruction loss, and KL divergence loss for a given input and condition.\n",
    "\n",
    "        Parameters:\n",
    "            x (tensor): The input tensor.\n",
    "            condition (tensor): The condition tensor.\n",
    "\n",
    "        Returns:\n",
    "            total_loss (tensor): The total loss.\n",
    "            reconstruction_loss (tensor): The reconstruction loss.\n",
    "            kl_loss (tensor): The KL divergence loss.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder([x, condition])\n",
    "        reconstruction = self.decoder([z, condition])\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.mse(x, reconstruction),\n",
    "                axis=(0, 1),\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Performs a single training step on the given data.\n",
    "\n",
    "        Args:\n",
    "            data: A tuple containing the input data `x` and the condition `condition`.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the following metrics:\n",
    "            - \"loss\": The total loss value.\n",
    "            - \"reconstruction_loss\": The reconstruction loss value.\n",
    "            - \"kl_loss\": The KL divergence loss value.\n",
    "        \"\"\"\n",
    "        x, condition = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        \"\"\"\n",
    "        Perform a single testing step of the model.\n",
    "\n",
    "        Args:\n",
    "            data (tuple): A tuple containing the input data `x` and the condition `condition`.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the calculated losses for the testing step, including the total loss, reconstruction loss, and KL loss.\n",
    "        \"\"\"\n",
    "        x, condition = data\n",
    "        total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def save_weights(self, model_dir, file_pref):\n",
    "        encoder_wts = self.encoder.get_weights()\n",
    "        decoder_wts = self.decoder.get_weights()\n",
    "        joblib.dump(encoder_wts, os.path.join(model_dir, f\"{file_pref}encoder_wts.h5\"))\n",
    "        joblib.dump(decoder_wts, os.path.join(model_dir, f\"{file_pref}decoder_wts.h5\"))\n",
    "\n",
    "    def load_weights(self, model_dir, file_pref):\n",
    "        encoder_wts = joblib.load(os.path.join(model_dir, f\"{file_pref}encoder_wts.h5\"))\n",
    "        decoder_wts = joblib.load(os.path.join(model_dir, f\"{file_pref}decoder_wts.h5\"))\n",
    "        self.encoder.set_weights(encoder_wts)\n",
    "        self.decoder.set_weights(decoder_wts)\n",
    "\n",
    "    def save(self, model_dir, file_pref):\n",
    "        self.save_weights(model_dir, file_pref)\n",
    "        dict_params = {\n",
    "            \"int_dim\": self.int_dim,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"num_features\": self.num_features,\n",
    "            \"time_steps\": self.time_steps,\n",
    "            \"condition_dim\": self.condition_dim,\n",
    "        }\n",
    "        params_file = os.path.join(model_dir, f\"{file_pref}parameters.pkl\")\n",
    "        joblib.dump(dict_params, params_file)\n",
    "        \n",
    "    def generate_samples(self, n, condition):\n",
    "        '''\n",
    "            Generate random samples from the LSTM VAE.\n",
    "\n",
    "            n : int : The number of samples to generate.\n",
    "            condition : numpy array : The condition to generate the samples for.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            A numpy array of shape (n, time_steps, number_of_features) containing the generated samples.\n",
    "        '''\n",
    "\n",
    "        # Sample from the standard normal distribution\n",
    "        z_samples = np.random.normal(size=(n, self.latent_dim))\n",
    "\n",
    "        # Decode the samples\n",
    "        gen = self.decoder.predict([z_samples, np.repeat(condition, n, axis=0)])\n",
    "\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Concatenate, Flatten, RNN\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import shape\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.rnn import PeepholeLSTMCell\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Source: https://github.com/meliksahturker/LSTM-VAE/tree/main?tab=readme-ov-file \n",
    "\n",
    "class LSTM_VAE(Model):\n",
    "    def __init__(self, input_shape, int_dim=36, latent_dim=18, condition_dim=1, batch_size=32, learning_rate=0.001, reconstruction_wt = 1.0, seed=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.int_dim = int_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_features = input_shape[2]\n",
    "        self.time_steps = input_shape[1]\n",
    "        self.condition_dim = condition_dim\n",
    "        self.condition_input = Input(shape=(condition_dim,)) # Shape of the condition input\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reconstruction_wt = reconstruction_wt\n",
    "        self.seed = seed\n",
    "        self.layer_seed = 0 \n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            tf.random.set_seed(self.seed)\n",
    "            \n",
    "        # Everything needed for the encoder and decoder should be defined before calling the encoder and decoder functions\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    def build_encoder(self):\n",
    "        \"\"\"\n",
    "        Builds the encoder part of the VAE.\n",
    "        \"\"\"\n",
    "\n",
    "        def Sampling(args):\n",
    "            \"\"\"\n",
    "            Sampling function for the VAE.\n",
    "            Parameters: args (tuple): Tuple containing the mean and log variance of the latent space.\n",
    "            Returns: Sampled latent space vector.\n",
    "            \"\"\"\n",
    "            z_mean, z_log_var = args\n",
    "            batch_size = shape(z_mean)[0] # Number of samples in the batch\n",
    "            latent_dim = shape(z_mean)[1] # Dimensionality of the latent space\n",
    "            epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0, stddev=1) # epsilon = irreducible error. Generates random noise to add to our reparameterisation trick value\n",
    "            # Reparameterisation trick\n",
    "            # - `K.exp()` takes the exponential of our log variance to obtain the variance. \n",
    "            # - `z_log_var / 2` is equivalent to taking the square root of the variance (standard deviation)\n",
    "            # - `* epsilon` to get a random value from a normal distribution with mean 0 and standard deviation 1\n",
    "            return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "        # --------------------- ENCODER ---------------------\n",
    "        # Creating the input layer\n",
    "        x = Input(shape=(self.time_steps, self.num_features))  # Keras adds None to the shape for the batch size: (None, time_steps, number_of_features)\n",
    "        encoder_input = Concatenate()([x, RepeatVector(self.time_steps)(self.condition_input)]) # Repeat condition for each timsestep. \n",
    "\n",
    "        # Creating the LSTM layers\n",
    "        encoder_LSTM_intermediate = RNN(PeepholeLSTMCell(self.int_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True, name=\"encoder_LSTM_intermediate\")(encoder_input)\n",
    "        self.layer_seed += 1\n",
    "        encoder_LSTM_latent = RNN(PeepholeLSTMCell(self.latent_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=False, name=\"encoder_LSTM_latent\")(encoder_LSTM_intermediate)\n",
    "        self.layer_seed += 1\n",
    "\n",
    "        # NOTE: GlorotUniform is equivalent to Xavier activation function (recommended with tanh activation functions, the default in LSTMs).\n",
    "\n",
    "        # These layers' outputs will be trained to represent the mean and log variance of the latent space\n",
    "        z_mean = Dense(self.latent_dim, name=\"z_mean\")(encoder_LSTM_latent) # Mean(s) of the latent space\n",
    "        z_log_var = Dense(self.latent_dim, name=\"z_log_var\")(encoder_LSTM_latent) # Log variance(s) of the latent space. Log is used to ensure so its exponent (which we'll calculate later) is always positive.\n",
    "\n",
    "        # A Lambda layer is used to sample from the latent space by passing the mean and log variance to the vae_sampling function\n",
    "        z = Lambda(Sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "        encoder = Model(inputs=[x, self.condition_input], outputs=[z_mean, z_log_var, z], name=\"encoder\") # z_mean and z_log_sigma are returned for loss calculation, z_encoder_output is the output of the encoder and will be used as input to the decoder\n",
    "\n",
    "        # SIDENOTE: Keras is able to trace back the computation graph from the output of the encoder to the input, so it will infer the structure of the encoder from its output and input layers.\n",
    "\n",
    "        return encoder\n",
    "\n",
    "    def build_decoder(self):\n",
    "        \"\"\"\n",
    "        Builds the decoder part of the VAE.\n",
    "        \"\"\"\n",
    "        decoder_input = Input(shape=(self.latent_dim,)) # Input to the decoder is the latent space vector z\n",
    "        condition_input_repeated = Flatten()(RepeatVector(self.latent_dim)(self.condition_input))\n",
    "        decoder_input_concat = Concatenate()([decoder_input, condition_input_repeated])\n",
    "        decoder_repeated = RepeatVector(self.time_steps)(decoder_input_concat) # Repeats the latent space vector (z) for the number of time steps, to match the input shape of the LSTM.\n",
    "        decoder_LSTM_intermediate = RNN(PeepholeLSTMCell(self.int_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True)(decoder_repeated) # Transforms (batch_size, time_steps, latent_dim) to (batch_size, time_steps, int_dim). \n",
    "        self.layer_seed += 1\n",
    "        decoder_LSTM = RNN(PeepholeLSTMCell(self.num_features, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True)(decoder_LSTM_intermediate)\n",
    "        decoder_output = TimeDistributed(Dense(self.num_features))(decoder_LSTM) # Contains Dense layer at the end to be able to produce high absolute values, since LSTM activations are tanh.\n",
    "        decoder = Model(inputs=[decoder_input, self.condition_input], outputs=decoder_output, name=\"decoder\") \n",
    "        \n",
    "        return decoder\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "            \"\"\"\n",
    "            Returns a list of metrics used for tracking during training.\n",
    "            Returns:list: A list of metrics including total loss, reconstruction loss, and KL divergence loss.\n",
    "            \"\"\"\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker,\n",
    "            ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the model.\n",
    "        Args: inputs: The input data.\n",
    "        Returns: The reconstructed output.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction\n",
    "\n",
    "    def calculate_losses(self, x, condition):\n",
    "        \"\"\"\n",
    "        Calculates the total loss, reconstruction loss, and KL divergence loss for a given input and condition.\n",
    "\n",
    "        Parameters:\n",
    "            x (tensor): The input tensor.\n",
    "            condition (tensor): The condition tensor.\n",
    "\n",
    "        Returns:\n",
    "            total_loss (tensor): The total loss.\n",
    "            reconstruction_loss (tensor): The reconstruction loss.\n",
    "            kl_loss (tensor): The KL divergence loss.\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var, z = self.encoder([x, condition])\n",
    "        reconstruction = self.decoder([z, condition])\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.mse(x, reconstruction),\n",
    "                axis=(0, 1),\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        total_loss = self.reconstruction_wt * reconstruction_loss + kl_loss\n",
    "        return total_loss, reconstruction_loss, kl_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Performs a single training step on the given data.\n",
    "\n",
    "        Args:\n",
    "            data: A tuple containing the input data `x` and the condition `condition`.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing the following metrics:\n",
    "            - \"loss\": The total loss value.\n",
    "            - \"reconstruction_loss\": The reconstruction loss value.\n",
    "            - \"kl_loss\": The KL divergence loss value.\n",
    "        \"\"\"\n",
    "        \n",
    "        x, condition = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        \"\"\"\n",
    "        Perform a single testing step of the model.\n",
    "\n",
    "        Args:\n",
    "            data (tuple): A tuple containing the input data `x` and the condition `condition`.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the calculated losses for the testing step, including the total loss, reconstruction loss, and KL loss.\n",
    "        \"\"\"\n",
    "        x, condition = data\n",
    "        \n",
    "        total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def save_weights(self, filepath):\n",
    "        model_dir, filename = os.path.split(filepath)\n",
    "\n",
    "        encoder_wts = self.encoder.get_weights()\n",
    "        decoder_wts = self.decoder.get_weights()\n",
    "        joblib.dump(encoder_wts, os.path.join(model_dir, f\"{filename}_encoder_wts.h5\"))\n",
    "        joblib.dump(decoder_wts, os.path.join(model_dir, f\"{filename}_decoder_wts.h5\"))\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        model_dir, filename = os.path.split(filepath)\n",
    "\n",
    "        print(f\"{file_pref}_encoder_wts.h5\")\n",
    "        encoder_wts = joblib.load(os.path.join(model_dir, f\"{filename}_encoder_wts.h5\"))\n",
    "        decoder_wts = joblib.load(os.path.join(model_dir, f\"{filename}_decoder_wts.h5\"))\n",
    "        self.encoder.set_weights(encoder_wts)\n",
    "        self.decoder.set_weights(decoder_wts)\n",
    "\n",
    "    def save(self, filepath, overwrite=True, options=None):\n",
    "        model_dir, filename = os.path.split(filepath)\n",
    "        \n",
    "        params_file = os.path.join(model_dir, f\"{filename}_parameters.pkl\")\n",
    "\n",
    "        if not overwrite and os.path.exists(weights_file) and os.path.exists(params_file):\n",
    "            return\n",
    "\n",
    "        self.save_weights(filepath)\n",
    "        \n",
    "        dict_params = {\n",
    "            \"int_dim\": self.int_dim,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"num_features\": self.num_features,\n",
    "            \"time_steps\": self.time_steps,\n",
    "            \"condition_dim\": self.condition_dim,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"batch_size\": self.batch_size,\n",
    "        }\n",
    "        joblib.dump(dict_params, params_file)\n",
    "        \n",
    "    def generate_samples(self, n, condition):\n",
    "        '''\n",
    "            Generate random samples from the LSTM VAE.\n",
    "\n",
    "            n : int : The number of samples to generate.\n",
    "            condition : numpy array : The condition to generate the samples for.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            A numpy array of shape (n, time_steps, number_of_features) containing the generated samples.\n",
    "        '''\n",
    "\n",
    "        # Sample from the standard normal distribution\n",
    "        z_samples = np.random.normal(size=(n, self.latent_dim))\n",
    "\n",
    "        # Decode the samples\n",
    "        gen = self.decoder.predict([z_samples, np.repeat(condition, n, axis=0)])\n",
    "\n",
    "        return gen\n",
    "        \n",
    "class PrintModelPerEpoch(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, print_weights=False):\n",
    "        super().__init__()\n",
    "        self.print_weights = print_weights\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(\"##########################################\")\n",
    "        for model in [self.model.encoder, self.model.decoder]:\n",
    "            print(f\"Model: {model.name}\")\n",
    "            for layer in model.layers:\n",
    "                print(f\"{layer.name}, input shape: {layer.input_shape}\")\n",
    "                if self.print_weights and layer.weights:\n",
    "                    for weight in layer.weights:\n",
    "                        weight_values = weight.numpy()\n",
    "                        print(f\"{layer.name}, weights: {weight.name}, mean: {weight_values.mean()}, variance: {weight_values.var()}\")\n",
    "            if model == self.model.encoder: print(\"------------------------------------------\")\n",
    "            else: print(\"##########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping # , ModelCheckpoint\n",
    "import pickle \n",
    "import os \n",
    "\n",
    "# https://discuss.tensorflow.org/t/valueerror-when-saving-autoencoder-tf-example/18618\n",
    "\n",
    "# Defining hyperparameters\n",
    "params = {'batch_size': 64, 'int_dim': 36, 'latent_dim': 12, 'learning_rate' : 0.0001}\n",
    "\n",
    "# Initializing and compiling the model\n",
    "vae = LSTM_VAE(input_shape=X_train.shape, int_dim=int(params['int_dim']), latent_dim=int(params['latent_dim']), seed=42)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']))\n",
    "\n",
    "# Define the checkpoint callback\n",
    "base_model_name = f\"model.bs{params['batch_size']}.id{params['int_dim']}.ld{params['latent_dim']}.lr{params['learning_rate']}\"\n",
    "\n",
    "# Add to display inputs and weights per epoch\n",
    "print_input_shape_callback = PrintModelPerEpoch(print_weights=True)\n",
    "\n",
    "os.makedirs(f\"output/models/{base_model_name}\", exist_ok=True)\n",
    "\n",
    "checkpoint_filepath = f\"output/models/{base_model_name}/{base_model_name}\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode=\"min\", patience=10)\n",
    "\n",
    "# Model fitting\n",
    "history = vae.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=int(params['batch_size']), callbacks=[early_stopping, checkpoint], epochs=250)\n",
    "\n",
    "# Save history and best_params as pickle files\n",
    "with open(f\"output/models/{base_model_name}/{base_model_name}_history.pkl\", 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# The model (that are considered the best) can be loaded as -\n",
    "# vae.load_weights(f\"output/ckpt/{base_model_name}\")\n",
    "\n",
    "# print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Lambda, Concatenate, Flatten, RNN\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import shape\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.rnn import PeepholeLSTMCell\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Source: https://github.com/meliksahturker/LSTM-VAE/tree/main?tab=readme-ov-file \n",
    "\n",
    "    class LSTM_VAE(Model):\n",
    "        def __init__(self, input_shape, int_dim=36, latent_dim=18, condition_dim=1, batch_size=32, learning_rate=0.001, reconstruction_wt = 2, seed=None, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.int_dim = int_dim\n",
    "            self.latent_dim = latent_dim\n",
    "            self.num_features = input_shape[2]\n",
    "            self.time_steps = input_shape[1]\n",
    "            self.condition_dim = condition_dim\n",
    "            self.condition_input = Input(shape=(condition_dim,)) # Shape of the condition input\n",
    "            self.batch_size = batch_size\n",
    "            self.learning_rate = learning_rate\n",
    "            self.reconstruction_wt = reconstruction_wt\n",
    "            self.seed = seed\n",
    "            self.layer_seed = 0 \n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed)\n",
    "                tf.random.set_seed(self.seed)\n",
    "                \n",
    "            # Everything needed for the encoder and decoder should be defined before calling the encoder and decoder functions\n",
    "            self.encoder = self.build_encoder()\n",
    "            self.decoder = self.build_decoder()\n",
    "            self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "            self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "            self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        \n",
    "        def build_encoder(self):\n",
    "            \"\"\"\n",
    "            Builds the encoder part of the VAE.\n",
    "            \"\"\"\n",
    "    \n",
    "            def Sampling(args):\n",
    "                \"\"\"\n",
    "                Sampling function for the VAE.\n",
    "                Parameters: args (tuple): Tuple containing the mean and log variance of the latent space.\n",
    "                Returns: Sampled latent space vector.\n",
    "                \"\"\"\n",
    "                z_mean, z_log_var = args\n",
    "                batch_size = shape(z_mean)[0] # Number of samples in the batch\n",
    "                latent_dim = shape(z_mean)[1] # Dimensionality of the latent space\n",
    "                epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0, stddev=1) # epsilon = irreducible error. Generates random noise to add to our reparameterisation trick value\n",
    "                # Reparameterisation trick\n",
    "                # - `K.exp()` takes the exponential of our log variance to obtain the variance. \n",
    "                # - `z_log_var / 2` is equivalent to taking the square root of the variance (standard deviation)\n",
    "                # - `* epsilon` to get a random value from a normal distribution with mean 0 and standard deviation 1\n",
    "                return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    \n",
    "            # --------------------- ENCODER ---------------------\n",
    "            # Creating the input layer\n",
    "            x = Input(shape=(self.time_steps, self.num_features))  # Keras adds None to the shape for the batch size: (None, time_steps, number_of_features)\n",
    "            encoder_input = Concatenate()([x, RepeatVector(self.time_steps)(self.condition_input)]) # Repeat condition for each timsestep. \n",
    "    \n",
    "            # Creating the LSTM layers\n",
    "            encoder_LSTM_intermediate = RNN(PeepholeLSTMCell(self.int_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True, name=\"encoder_LSTM_intermediate\")(encoder_input)\n",
    "            self.layer_seed += 1\n",
    "            encoder_LSTM_latent = RNN(PeepholeLSTMCell(self.latent_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=False, name=\"encoder_LSTM_latent\")(encoder_LSTM_intermediate)\n",
    "            self.layer_seed += 1\n",
    "    \n",
    "            # NOTE: GlorotUniform is equivalent to Xavier activation function (recommended with tanh activation functions, the default in LSTMs).\n",
    "    \n",
    "            # These layers' outputs will be trained to represent the mean and log variance of the latent space\n",
    "            z_mean = Dense(self.latent_dim, name=\"z_mean\")(encoder_LSTM_latent) # Mean(s) of the latent space\n",
    "            z_log_var = Dense(self.latent_dim, name=\"z_log_var\")(encoder_LSTM_latent) # Log variance(s) of the latent space. Log is used to ensure so its exponent (which we'll calculate later) is always positive.\n",
    "    \n",
    "            # A Lambda layer is used to sample from the latent space by passing the mean and log variance to the vae_sampling function\n",
    "            z = Lambda(Sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "    \n",
    "            encoder = Model(inputs=[x, self.condition_input], outputs=[z_mean, z_log_var, z], name=\"encoder\") # z_mean and z_log_sigma are returned for loss calculation, z_encoder_output is the output of the encoder and will be used as input to the decoder\n",
    "    \n",
    "            # SIDENOTE: Keras is able to trace back the computation graph from the output of the encoder to the input, so it will infer the structure of the encoder from its output and input layers.\n",
    "    \n",
    "            return encoder\n",
    "    \n",
    "        def build_decoder(self):\n",
    "            \"\"\"\n",
    "            Builds the decoder part of the VAE.\n",
    "            \"\"\"\n",
    "            decoder_input = Input(shape=(self.latent_dim,)) # Input to the decoder is the latent space vector z\n",
    "            condition_input_repeated = Flatten()(RepeatVector(self.latent_dim)(self.condition_input))\n",
    "            decoder_input_concat = Concatenate()([decoder_input, condition_input_repeated])\n",
    "            decoder_repeated = RepeatVector(self.time_steps)(decoder_input_concat) # Repeats the latent space vector (z) for the number of time steps, to match the input shape of the LSTM.\n",
    "            decoder_LSTM_intermediate = RNN(PeepholeLSTMCell(self.int_dim, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True)(decoder_repeated) # Transforms (batch_size, time_steps, latent_dim) to (batch_size, time_steps, int_dim). \n",
    "            self.layer_seed += 1\n",
    "            decoder_LSTM = RNN(PeepholeLSTMCell(self.num_features, kernel_initializer=GlorotUniform(seed=self.seed + self.layer_seed)), return_sequences=True)(decoder_LSTM_intermediate)\n",
    "            decoder_output = TimeDistributed(Dense(self.num_features))(decoder_LSTM) # Contains Dense layer at the end to be able to produce high absolute values, since LSTM activations are tanh.\n",
    "            decoder = Model(inputs=[decoder_input, self.condition_input], outputs=decoder_output, name=\"decoder\") \n",
    "            \n",
    "            return decoder\n",
    "    \n",
    "        @property\n",
    "        def metrics(self):\n",
    "                \"\"\"\n",
    "                Returns a list of metrics used for tracking during training.\n",
    "                Returns:list: A list of metrics including total loss, reconstruction loss, and KL divergence loss.\n",
    "                \"\"\"\n",
    "                return [\n",
    "                    self.total_loss_tracker,\n",
    "                    self.reconstruction_loss_tracker,\n",
    "                    self.kl_loss_tracker,\n",
    "                ]\n",
    "    \n",
    "        def call(self, inputs):\n",
    "            \"\"\"\n",
    "            Performs the forward pass of the model.\n",
    "            Args: inputs: The input data.\n",
    "            Returns: The reconstructed output.\n",
    "            \"\"\"\n",
    "            z_mean, z_log_var, z = self.encoder(inputs)\n",
    "            reconstruction = self.decoder(z)\n",
    "            return reconstruction\n",
    "    \n",
    "        def calculate_losses(self, x, condition):\n",
    "            \"\"\"\n",
    "            Calculates the total loss, reconstruction loss, and KL divergence loss for a given input and condition.\n",
    "    \n",
    "            Parameters:\n",
    "                x (tensor): The input tensor.\n",
    "                condition (tensor): The condition tensor.\n",
    "    \n",
    "            Returns:\n",
    "                total_loss (tensor): The total loss.\n",
    "                reconstruction_loss (tensor): The reconstruction loss.\n",
    "                kl_loss (tensor): The KL divergence loss.\n",
    "            \"\"\"\n",
    "            z_mean, z_log_var, z = self.encoder([x, condition])\n",
    "            reconstruction = self.decoder([z, condition])\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mse(x, reconstruction),\n",
    "                    axis=(0, 1),\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            reconstruction_loss = self.reconstruction_wt * reconstruction_loss\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            return total_loss, reconstruction_loss, kl_loss\n",
    "    \n",
    "        @tf.function\n",
    "        def train_step(self, data):\n",
    "            \"\"\"\n",
    "            Performs a single training step on the given data.\n",
    "    \n",
    "            Args:\n",
    "                data: A tuple containing the input data `x` and the condition `condition`.\n",
    "    \n",
    "            Returns:\n",
    "                A dictionary containing the following metrics:\n",
    "                - \"loss\": The total loss value.\n",
    "                - \"reconstruction_loss\": The reconstruction loss value.\n",
    "                - \"kl_loss\": The KL divergence loss value.\n",
    "            \"\"\"\n",
    "            \n",
    "            x, condition = data\n",
    "            with tf.GradientTape() as tape:\n",
    "                total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "                \n",
    "            grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            \n",
    "            self.total_loss_tracker.update_state(total_loss)\n",
    "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "            self.kl_loss_tracker.update_state(kl_loss)\n",
    "            return {\n",
    "                \"loss\": self.total_loss_tracker.result(),\n",
    "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            }\n",
    "    \n",
    "        @tf.function\n",
    "        def test_step(self, data):\n",
    "            \"\"\"\n",
    "            Perform a single testing step of the model.\n",
    "    \n",
    "            Args:\n",
    "                data (tuple): A tuple containing the input data `x` and the condition `condition`.\n",
    "    \n",
    "            Returns:\n",
    "                dict: A dictionary containing the calculated losses for the testing step, including the total loss, reconstruction loss, and KL loss.\n",
    "            \"\"\"\n",
    "            x, condition = data\n",
    "            \n",
    "            total_loss, reconstruction_loss, kl_loss = self.calculate_losses(x, condition)\n",
    "            self.total_loss_tracker.update_state(total_loss)\n",
    "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "            self.kl_loss_tracker.update_state(kl_loss)\n",
    "            return {\n",
    "                \"loss\": self.total_loss_tracker.result(),\n",
    "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            }\n",
    "    \n",
    "        def save_weights(self, filepath):\n",
    "            model_dir, filename = os.path.split(filepath)\n",
    "    \n",
    "            encoder_wts = self.encoder.get_weights()\n",
    "            decoder_wts = self.decoder.get_weights()\n",
    "            joblib.dump(encoder_wts, os.path.join(model_dir, f\"{filename}_encoder_wts.h5\"))\n",
    "            joblib.dump(decoder_wts, os.path.join(model_dir, f\"{filename}_decoder_wts.h5\"))\n",
    "    \n",
    "        def load_weights(self, filepath):\n",
    "            model_dir, filename = os.path.split(filepath)\n",
    "    \n",
    "            print(f\"{file_pref}_encoder_wts.h5\")\n",
    "            encoder_wts = joblib.load(os.path.join(model_dir, f\"{filename}_encoder_wts.h5\"))\n",
    "            decoder_wts = joblib.load(os.path.join(model_dir, f\"{filename}_decoder_wts.h5\"))\n",
    "            self.encoder.set_weights(encoder_wts)\n",
    "            self.decoder.set_weights(decoder_wts)\n",
    "    \n",
    "        def save(self, filepath, overwrite=True, options=None):\n",
    "            model_dir, filename = os.path.split(filepath)\n",
    "            \n",
    "            params_file = os.path.join(model_dir, f\"{filename}_parameters.pkl\")\n",
    "    \n",
    "            if not overwrite and os.path.exists(weights_file) and os.path.exists(params_file):\n",
    "                return\n",
    "    \n",
    "            self.save_weights(filepath)\n",
    "            \n",
    "            dict_params = {\n",
    "                \"int_dim\": self.int_dim,\n",
    "                \"latent_dim\": self.latent_dim,\n",
    "                \"num_features\": self.num_features,\n",
    "                \"time_steps\": self.time_steps,\n",
    "                \"condition_dim\": self.condition_dim,\n",
    "                \"learning_rate\": self.learning_rate,\n",
    "                \"batch_size\": self.batch_size,\n",
    "            }\n",
    "            joblib.dump(dict_params, params_file)\n",
    "            \n",
    "        def generate_samples(self, n, condition):\n",
    "            '''\n",
    "                Generate random samples from the LSTM VAE.\n",
    "    \n",
    "                n : int : The number of samples to generate.\n",
    "                condition : numpy array : The condition to generate the samples for.\n",
    "    \n",
    "                Returns\n",
    "                -------\n",
    "                A numpy array of shape (n, time_steps, number_of_features) containing the generated samples.\n",
    "            '''\n",
    "    \n",
    "            # Sample from the standard normal distribution\n",
    "            z_samples = np.random.normal(size=(n, self.latent_dim))\n",
    "    \n",
    "            # Decode the samples\n",
    "            gen = self.decoder.predict([z_samples, np.repeat(condition, n, axis=0)])\n",
    "    \n",
    "            return gen\n",
    "            \n",
    "    class PrintModelPerEpoch(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, print_weights=False):\n",
    "            super().__init__()\n",
    "            self.print_weights = print_weights\n",
    "    \n",
    "        def on_epoch_begin(self, epoch, logs=None):\n",
    "            print(\"##########################################\")\n",
    "            for model in [self.model.encoder, self.model.decoder]:\n",
    "                print(f\"Model: {model.name}\")\n",
    "                for layer in model.layers:\n",
    "                    print(f\"{layer.name}, input shape: {layer.input_shape}\")\n",
    "                    if self.print_weights and layer.weights:\n",
    "                        for weight in layer.weights:\n",
    "                            weight_values = weight.numpy()\n",
    "                            print(f\"{layer.name}, weights: {weight.name}, mean: {weight_values.mean()}, variance: {weight_values.var()}\")\n",
    "                if model == self.model.encoder: print(\"------------------------------------------\")\n",
    "                else: print(\"##########################################\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "else:\n",
    "    print(\"No errors occurred. LSTM-VAE class was successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `optimise_LSTM_VAE.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow pandas numpy matplotlib seaborn numpy scikit-learn hyperopt tensorflow_addons pydot graphviz visualkeras reload imblearn neurokit2\n",
    "\n",
    "import helpers as h\n",
    "from importlib import reload\n",
    "from LSTM_VAE import LSTM_VAE\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "reload(h)\n",
    "\n",
    "try:\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, p_train, p_val, p_test = h.prepare_train_val_test_sets(filenames=['input/dl_X_wl24_sr32.pkl', 'input/dl_y_wl24_sr32.pkl', 'input/dl_p_wl24_sr32.pkl'])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "else:\n",
    "    print(\"No errors occurred. Data partitioned successfully.\")\n",
    "\n",
    "#--------------------- Hyperparameter optimisation ---------------------------# \n",
    "from hyperopt import hp\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "import pickle\n",
    "\n",
    "filename = \"240430_hyperopt_best_params\"\n",
    "\n",
    "try:\n",
    "    # Define the hyperparameter space\n",
    "    space = {\n",
    "        'batch_size': hp.choice('batch_size', [32, 64]),\n",
    "        'int_dim': hp.choice('int_dim', [25, 50, 75, 100, 125, 150, 175, 200]),\n",
    "        'latent_dim': hp.choice('latent_dim', [7, 8, 10, 12, 14, 18, 24, 32, 48, 72, 96, 120]),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.1)),\n",
    "        'reconstruction_wt': hp.choice('reconstruction_wt', [1, 2, 3]),\n",
    "        'optimizer': hp.choice('optimizer', ['Adam', 'RMSprop'])\n",
    "    }\n",
    "\n",
    "    # Objective function\n",
    "    def objective(params):\n",
    "        vae = LSTM_VAE(input_shape=X_train.shape, int_dim=int(params['int_dim']), latent_dim=int(params['latent_dim']), reconstruction_wt = int(params['reconstruction_wt']), seed=42)    \n",
    "\n",
    "        if params['optimizer'] == 'Adam':\n",
    "            opt = keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "        elif params['optimizer'] == 'RMSprop':\n",
    "            opt = keras.optimizers.RMSprop(learning_rate=params['learning_rate'])\n",
    "\n",
    "        vae.compile(optimizer=opt)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', mode=\"min\", patience=10)\n",
    "        history = vae.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=int(params['batch_size']), callbacks=[early_stopping], epochs=1000, verbose=2) # callbacks=[early_stopping, checkpoint]\n",
    "        return np.min(history.history['val_loss'])\n",
    "\n",
    "    best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=Trials())\n",
    "\n",
    "    with open(f\"{filename}.pkl\", 'wb') as f:\n",
    "        pickle.dump(best_params, f)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "else: \n",
    "    print(f\"No errors occurred. Hyperparameter optimisation procedure completed successfully. Best parameters stored as: {filename}.pkl\")\n",
    "\n",
    "#--------------------- Training and storing the model ---------------------------# \n",
    "import os # https://discuss.tensorflow.org/t/valueerror-when-saving-autoencoder-tf-example/18618\n",
    "\n",
    "# Defining hyperparameters\n",
    "print(\"BEST PARAMETERS:\\n\", best_params)\n",
    "params = best_params\n",
    "\n",
    "# Initializing and compiling the model\n",
    "vae = LSTM_VAE(input_shape=X_train.shape, int_dim=int(params['int_dim']), latent_dim=int(params['latent_dim']), reconstruction_wt = int(params['reconstruction_wt']), seed=42)    \n",
    "if params['optimizer'] == 'Adam':\n",
    "    opt = keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
    "elif params['optimizer'] == 'RMSprop':\n",
    "    opt = keras.optimizers.RMSprop(learning_rate=params['learning_rate'])\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "# Define the checkpoint callback\n",
    "base_model_name = f\"model.bs{params['batch_size']}.id{params['int_dim']}.ld{params['latent_dim']}.lr{params['learning_rate']}.rw{params['reconstruction_wt']}\"\n",
    "os.makedirs(f\"output/models/{base_model_name}\", exist_ok=True)\n",
    "\n",
    "checkpoint_filepath = f\"output/models/{base_model_name}/{base_model_name}\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Defining Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode=\"min\", patience=10, restore_best_weights = True)\n",
    "\n",
    "# Fitting the model\n",
    "history = vae.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), batch_size=int(params['batch_size']), callbacks=[early_stopping, checkpoint], epochs=1000, verbose=2)\n",
    "\n",
    "# Save history and best_params as pickle files\n",
    "with open(f\"output/models/{base_model_name}/{base_model_name}_history.pkl\", 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
