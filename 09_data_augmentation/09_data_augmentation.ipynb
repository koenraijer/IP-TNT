{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Global settings\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 6)\n",
    "plt.style.use('ggplot') # nicer plots\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Data loading\n",
    "df = pd.read_csv('output/combined_feature_engineered_tnt_only.csv')\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df.drop(['datetime', 'unix_time', 'source', 'response', 'intrusion', 'intrusion_nothink', 'trialcode', 'session_id'], axis=1, inplace=True)\n",
    "\n",
    "X = df.drop('intrusion_tnt', axis=1)  # Features: All columns except 'intrusion_tnt'\n",
    "y = df['intrusion_tnt']  # Labels: 'intrusion_tnt' column\n",
    "\n",
    "# Assuming 'participant' is the column with participant IDs\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=df['participant']))\n",
    "\n",
    "# Create the training and test sets\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Initialize a new KNNImputer instance\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "knn_imputer.fit(X_train)\n",
    "\n",
    "# Transform the training and test data\n",
    "X_train = knn_imputer.transform(X_train)\n",
    "X_test = knn_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short literature review on (conditional) recurrent GANS\n",
    "- ([Nikolaidis, 2019-05-22](zotero://select/items/1_72NRYTCY)). Inspired by Esteban et al., no source code available. Focusses on application of synthetic data.\n",
    "- ([Esteban, 2017-12-03](zotero://select/items/2_DHLZEJRV)) --> source code: https://github.com/ratschlab/RGAN. Original paper.\n",
    "- [Conditional GAN using TorchGAN](https://torchgan.readthedocs.io/en/latest/modules/models.html?highlight=conditional#conditional-gan)\n",
    "\n",
    "Training GANs appears to be very hard: https://webcache.googleusercontent.com/search?q=cache:https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628&sca_esv=ff0dae4b23f8bbed&sca_upv=1&strip=1&vwsrc=0. \n",
    "\n",
    "Perhaps variational autoencoders are a better idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimeVAE_abudesai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvae_conv_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariationalAutoencoderConv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the VAE model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m vae \u001b[38;5;241m=\u001b[39m VariationalAutoencoderConv(\n\u001b[1;32m      5\u001b[0m     seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      6\u001b[0m     feat_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      7\u001b[0m     latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m     hidden_layer_sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/00_Werk_en_studie/Msc_Data_Science_&_Society/Thesis/Analysis/09_data_augmentation/timeVAE_abudesai/vae_conv_model.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# or any {'0', '1', '2'}\u001b[39;00m\n\u001b[1;32m      5\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1D,  Flatten, Dense, Conv1DTranspose, Reshape, Input\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from timeVAE_abudesai.vae_conv_model import VariationalAutoencoderConv\n",
    "\n",
    "# Initialize the VAE model\n",
    "vae = VariationalAutoencoderConv(\n",
    "    seq_len=2,\n",
    "    feat_dim=2,\n",
    "    latent_dim = 2,\n",
    "    hidden_layer_sizes=[100, 200],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
